{
 "cells": [
  {
   "cell_type": "raw",
   "id": "05db5129-9fd8-43d3-b724-516eed673e57",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6354b4c-48e0-472a-ae18-4d56bee269a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f933cc3-a2e2-4fd2-a9ab-806a87ba2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('font',**{'family':'serif',\n",
    "             'serif':['Times New Roman'],\n",
    "             'size': 12,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe9094-7d71-4295-9fca-091413d65a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_accuracy(df_, margin=0):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "    df_ties = df_[df_.label_r == 0]\n",
    "\n",
    "    # Split non ties per their outcome (left and right)\n",
    "    df_nonties_left = df_nonties[(df_nonties.label_r == -1)]\n",
    "    df_nonties_right = df_nonties[(df_nonties.label_r == 1)]\n",
    "\n",
    "    # Non-ties accuracy\n",
    "    correct_left = ((df_nonties.label_r == -1) & (df_nonties.rank_left - df_nonties.rank_right > margin)).sum()\n",
    "    correct_right = ((df_nonties.label_r == 1) & (df_nonties.rank_right - df_nonties.rank_left > margin)).sum()\n",
    "\n",
    "    nontie_left_accuracy = correct_left / (df_nonties.label_r == -1).sum()\n",
    "    nontie_right_accuracy = correct_right / (df_nonties.label_r == 1).sum()\n",
    "    nontie_accuracy = (correct_left + correct_right ) / df_nonties.shape[0]\n",
    "    \n",
    "    # Ties accuracy\n",
    "    tie_accuracy = (abs(df_ties.rank_left - df_ties.rank_right) < margin).sum() / df_ties.shape[0]\n",
    "\n",
    "    # Overall accuracy\n",
    "    overall_accuracy = X_test[((df_.label_r == -1) & (df_.rank_left - df_.rank_right > margin)) |\n",
    "                              ((df_.label_r ==  1) & (df_.rank_right - df_.rank_left > margin)) |\n",
    "                              ((df_.label_r ==  0) & (abs(df_.rank_left - df_.rank_right) < margin))].shape[0] / df_.shape[0]\n",
    "    \n",
    "    return nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaac611-bd51-4155-9251-3aaf42bb7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_accuracy_nomargin(df_,):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "\n",
    "    # Split non ties per their outcome (left and right)\n",
    "    df_nonties_left = df_nonties[(df_nonties.label_r == -1)]\n",
    "    df_nonties_right = df_nonties[(df_nonties.label_r == 1)]\n",
    "\n",
    "    # Non-ties accuracy\n",
    "    correct_left = ((df_nonties.label_r == -1) & (df_nonties.rank_left - df_nonties.rank_right > 0)).sum()\n",
    "    correct_right = ((df_nonties.label_r == 1) & (df_nonties.rank_right - df_nonties.rank_left > 0)).sum()\n",
    "\n",
    "    nontie_left_accuracy = correct_left / (df_nonties.label_r == -1).sum()\n",
    "    nontie_right_accuracy = correct_right / (df_nonties.label_r == 1).sum()\n",
    "    nontie_accuracy = (correct_left + correct_right ) / df_nonties.shape[0]\n",
    "\n",
    "    return nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b642d78-1fc5-4ab0-a843-52522f41b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_distance(df_):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "    df_ties = df_[df_.label_r == 0]\n",
    "\n",
    "    # Distance between non-ties\n",
    "    avg_dist_nonties = abs(df_nonties.rank_left - df_nonties.rank_right).mean()\n",
    "    \n",
    "    # Distance between ties\n",
    "    avg_dist_ties = abs(df_ties.rank_left - df_ties.rank_right).mean()\n",
    "    \n",
    "    return avg_dist_nonties, avg_dist_ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3bea7-c736-4e4c-96e7-e2926d043b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_distance_all(df_):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "    df_ties = df_[df_.label_r == 0]\n",
    "\n",
    "    # Distance between non-ties\n",
    "    avg_dist_nonties = abs(df_nonties.rank_left - df_nonties.rank_right).values\n",
    "    \n",
    "    # Distance between ties\n",
    "    avg_dist_ties = abs(df_ties.rank_left - df_ties.rank_right).values\n",
    "    \n",
    "    all_avg_dist = np.concatenate((avg_dist_nonties, avg_dist_ties)).mean()\n",
    "    \n",
    "    return all_avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66dd3f-8919-4b14-85dc-af676dc96fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_distance_sum(df_):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "    df_ties = df_[df_.label_r == 0]\n",
    "\n",
    "    # Distance between non-ties\n",
    "    sum_dist_nonties = abs(df_nonties.rank_left - df_nonties.rank_right).sum()\n",
    "    \n",
    "    # Distance between ties\n",
    "    sum_dist_ties = abs(df_ties.rank_left - df_ties.rank_right).sum()\n",
    "    \n",
    "    return sum_dist_nonties, sum_dist_ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f023dd-8aaf-4fe7-9ba9-14cb2c16986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(df_):\n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "    if 'logits_0' in df_.columns:\n",
    "        col1_values = df_['logits_l'].values\n",
    "        col2_values = df_['logits_0'].values\n",
    "        col3_values = df_['logits_r'].values\n",
    "            \n",
    "        probabilities = np.apply_along_axis(softmax, axis=1, arr=np.column_stack((col1_values, col2_values, col3_values)))\n",
    "        max_indices = np.argmax(probabilities, axis=1)\n",
    "        # Convert the probabilities back to a DataFrame with appropriate column names\n",
    "        softmax_df = pd.DataFrame(probabilities, columns=['softmax_logit_l', 'softmax_logit_0', 'softmax_logit_r'])\n",
    "        max_index_df = pd.DataFrame({'class_predicted': max_indices})\n",
    "        # Concatenate the new DataFrame with the original DataFrame if needed\n",
    "        result_df = pd.concat([df.reset_index(drop=True), softmax_df, max_index_df], axis=1,)\n",
    "    \n",
    "        all_accuracy = (result_df.class_predicted == result_df.label_c).sum() / result_df.shape[0]\n",
    "        tie_accuracy = (result_df[result_df.label_c == 1].class_predicted == result_df[result_df.label_c == 1].label_c).sum() / result_df.shape[0]\n",
    "        nontie_accuracy = (result_df[result_df.label_c != 1].class_predicted == result_df[result_df.label_c != 1].label_c).sum() / result_df.shape[0]\n",
    "    \n",
    "    # Without ties\n",
    "    else:\n",
    "        col1_values = df_['logits_l'].values\n",
    "        col3_values = df_['logits_r'].values\n",
    "            \n",
    "        probabilities = np.apply_along_axis(softmax, axis=1, arr=np.column_stack((col1_values, col3_values)))\n",
    "        max_indices = np.argmax(probabilities, axis=1)\n",
    "        # Convert the probabilities back to a DataFrame with appropriate column names\n",
    "        softmax_df = pd.DataFrame(probabilities, columns=['softmax_logit_l', 'softmax_logit_r'])\n",
    "        max_index_df = pd.DataFrame({'class_predicted': max_indices})\n",
    "        # Concatenate the new DataFrame with the original DataFrame if needed\n",
    "        result_df = pd.concat([df.reset_index(drop=True), softmax_df, max_index_df], axis=1,)\n",
    "    \n",
    "        all_accuracy = (result_df.class_predicted == result_df.label_c).sum() / result_df.shape[0]\n",
    "        tie_accuracy = 0\n",
    "        nontie_accuracy = all_accuracy\n",
    "        \n",
    "    return all_accuracy, tie_accuracy, nontie_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab6335-3ce4-4ff6-b403-ca13848c444c",
   "metadata": {},
   "source": [
    "# Margins Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c936a-f55e-4fec-9e83-ecbcf5c11da2",
   "metadata": {},
   "source": [
    "## Trained with ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67609ec3-fabc-41db-858d-b441dcb6b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = glob('../outputs/saved/margin-*.pkl')\n",
    "compiled_results = []\n",
    "for model_result in model_results:\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = float(os.path.basename(model_result).replace('margin-', '').replace('.pt_results.pkl', ''))\n",
    "    seed = 30\n",
    "    print('Margin:', margin_, '-->', model_result)\n",
    "\n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "    # Ranking sub-network\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_)\n",
    "\n",
    "    # Ranking sub-network, without any margin on accuracy\n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "\n",
    "    # Classification sub-network\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "\n",
    "    # Rank difference\n",
    "    avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "    sum_dist_nonties, sum_dist_ties = compute_ranking_distance(X_test)\n",
    "    \n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'margin': margin_,\n",
    "        'seed': seed,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        'ranking_acc_left': nontie_left_accuracy,\n",
    "        'ranking_acc_right': nontie_right_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        'ranking_acc_left_nomargin': nontie_left_accuracy_nomargin,\n",
    "        'ranking_acc_right_nomargin': nontie_right_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'sum_dist_nonties': sum_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "        'sum_dist_ties': sum_dist_ties,\n",
    "    }\n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c01c0c-a129-44e5-99e8-e96ffb3036e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withties = results_df.sort_values(by=['margin'])\n",
    "df_withties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8066ff-ab30-43b4-a014-0bb3f05d4546",
   "metadata": {},
   "source": [
    "## Trained without ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a16be4-83dd-41bb-93eb-98bfaa65a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = glob('../outputs/saved/_noties-margin-*.pkl')\n",
    "compiled_results = []\n",
    "for model_result in model_results:\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = float(os.path.basename(model_result).replace('_noties-margin-', '').replace('.pt_results.pkl', ''))\n",
    "    seed = 30\n",
    "    print('Margin:', margin_, '-->', model_result)\n",
    "\n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "    # Ranking sub-network\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_)\n",
    "\n",
    "    # Ranking sub-network, without any margin on accuracy\n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "\n",
    "    # Classification sub-network\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "\n",
    "    # Rank difference\n",
    "    avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "    sum_dist_nonties, sum_dist_ties = compute_ranking_distance(X_test)\n",
    "    \n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'margin': margin_,\n",
    "        'seed': seed,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        'ranking_acc_left': nontie_left_accuracy,\n",
    "        'ranking_acc_right': nontie_right_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        'ranking_acc_left_nomargin': nontie_left_accuracy_nomargin,\n",
    "        'ranking_acc_right_nomargin': nontie_right_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'sum_dist_nonties': sum_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "        'sum_dist_ties': sum_dist_ties,\n",
    "    }\n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d999f-886f-40fb-ae32-a28720ba9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noties = results_df.sort_values(by=['margin'])\n",
    "df_noties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf36a7-0b09-4219-8dcd-1f29750a1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "plt.plot(df_withties.margin, df_withties.ranking_acc, 'k',                    label='Train w/ ties. Acc. w/ margin')\n",
    "plt.plot(df_withties.margin, df_withties.ranking_acc_nonties_nomargin, 'k--', label='Trained w/ ties. Acc. w/o margin', )\n",
    "plt.plot(df_noties.margin, df_noties.ranking_acc, 'r',                        label='Train w/o ties. Acc. w/ margin', )\n",
    "plt.plot(df_noties.margin, df_noties.ranking_acc_nonties_nomargin, 'r--',     label='Trained w/o ties. Acc. w/o margin', )\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(fontsize=\"9\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492cdb4-0798-44ab-a6ab-e4c696bb311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3.5))\n",
    "plt.plot(df_withties.margin, df_withties.ranking_acc_nonties_nomargin, 'k', label='Trained w/ ties.', )\n",
    "plt.plot(df_noties.margin, df_noties.ranking_acc_nonties_nomargin, 'r',     label='Trained w/o ties.', )\n",
    "\n",
    "plt.plot(qq.margin, [qq.ranking_acc_nonties[0] for i in range(0, 21, 1)], 'b--',     )\n",
    "\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(fontsize=\"11\")\n",
    "plt.show()\n",
    "fig.savefig('accuracy_nomargin.png', dpi=fig.dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8a24a-c6f5-465d-b7bc-022dfb413bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average accuracy difference between trained with and without ties:', (df_withties[df_withties.margin>0.4].ranking_acc_nonties_nomargin.reset_index(drop=True) - df_noties[df_noties.margin>0.4].ranking_acc_nonties_nomargin.reset_index(drop=True)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64212822-5b4d-4c7f-8318-9309e57f9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3.5))\n",
    "plt.plot(df_withties.margin, df_withties.ranking_acc, 'k',                    )#label='Trained w/ ties. ')\n",
    "#plt.plot(df_withties.margin, df_withties.ranking_acc_nonties_nomargin, 'k--', label='Trained w/ ties. Acc. w/o margin', )\n",
    "plt.plot(df_noties.margin, df_noties.ranking_acc, 'r',                        label='Trained w/o ties. ', )\n",
    "#plt.plot(df_noties.margin, df_noties.ranking_acc_nonties_nomargin, 'r--',     label='Trained w/o ties. Acc. w/o margin', )\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(fontsize=\"11\")\n",
    "plt.show()\n",
    "fig.savefig('accuracy_margin.png', dpi=fig.dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673857a3-cbb0-4ec5-8868-cc8601f9e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(df_withties.margin, df_withties.avg_dist_ties, 'k', label='Train w/ ties. Tie obs.')\n",
    "plt.plot(df_withties.margin, df_withties.avg_dist_nonties, 'k--', label='Train w/ ties. Non-tie obs.', )\n",
    "plt.plot(df_noties.margin, df_noties.avg_dist_ties, 'r', label='Train w/o ties. Ties obs.')\n",
    "plt.plot(df_noties.margin, df_noties.avg_dist_nonties, 'r--', label='Train w/o ties. Non-ties obs.')\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('Average Rank Difference')\n",
    "plt.legend(fontsize=\"9\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d3be3-9afa-4b38-9003-071d0080a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3))\n",
    "plt.plot(df_withties.margin, df_withties.avg_dist_ties,    'k',   label='Ties')\n",
    "plt.plot(df_withties.margin, df_withties.avg_dist_nonties, 'k--', label='Non-ties', )\n",
    "plt.plot([0., 2.], [0., 2.], 'b:', )\n",
    "#plt.plot(df_noties.margin, df_noties.avg_dist_ties, 'r', label='Train w/o ties. Ties obs.')\n",
    "#plt.plot(df_noties.margin, df_noties.avg_dist_nonties, 'r--', label='Train w/o ties. Non-ties obs.')\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('Average Rank Difference\\n in Comparisons')\n",
    "plt.legend(fontsize=\"9\")\n",
    "plt.show()\n",
    "fig.savefig('rank_difference.png', dpi=fig.dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8977b6-a163-421e-8171-a3a173a71bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(df_withties.margin, df_withties.sum_dist_ties / df_withties.sum_dist_nonties, 'k', label='Train w/ ties. Tie obs.')\n",
    "plt.plot(df_noties.margin, df_noties.sum_dist_ties / df_noties.sum_dist_nonties, 'r', label='Train w/ ties. Tie obs.')\n",
    "#plt.plot(df_withties.margin, df_withties.avg_dist_nonties, 'k--', label='Train w/ ties. Non-tie obs.', )\n",
    "#plt.plot(df_noties.margin, df_noties.avg_dist_ties, 'r', label='Train w/o ties. Ties obs.')\n",
    "#plt.plot(df_noties.margin, df_noties.avg_dist_nonties, 'r--', label='Train w/o ties. Non-ties obs.')\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('Average Rank Difference')\n",
    "plt.legend(fontsize=\"9\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4d716-0af2-4695-b3a4-fa34a3946afb",
   "metadata": {},
   "source": [
    "# What happens with wrongly classified observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfda1c2-a972-4fe2-88b1-ffd7e1d6db93",
   "metadata": {},
   "source": [
    "## With ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c27e0-61a8-4fd8-94fe-a40c185b2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in glob('../outputs/saved/margin-*.pkl'):\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin = float(os.path.basename(model_result).replace('margin-', '').replace('.pt_results.pkl', ''))\n",
    "    seed = 30\n",
    "    print('Margin:', margin, '-->', model_result)\n",
    "\n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "    collection = []\n",
    "    for image in X_test.image_left.unique():\n",
    "        rank_image = X_test[X_test.image_left == image].iloc[0].rank_left\n",
    "        collection.append({\n",
    "                'image': image,\n",
    "                'rank': rank_image, \n",
    "                'ties': ties,\n",
    "                'margin': margin_\n",
    "            }\n",
    "        )\n",
    "    for image in X_test.image_right.unique():\n",
    "        rank_image = X_test[X_test.image_right == image].iloc[0].rank_right\n",
    "        collection.append({\n",
    "                'image': image,\n",
    "                'rank': rank_image, \n",
    "                'ties': ties,\n",
    "                'margin': margin_          \n",
    "            }\n",
    "        )\n",
    "    image_ranks = pd.DataFrame(collection).drop_duplicates()\n",
    "    std = image_ranks['rank'].std()\n",
    "    min_max = image_ranks['rank'].max() - image_ranks['rank'].min()\n",
    "    \n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = X_test[X_test.label_r != 0].copy()\n",
    "    df_ties = X_test[X_test.label_r == 0].copy()\n",
    "\n",
    "    df_nonties['correct_left'] = ((df_nonties.label_r == -1) & (df_nonties.rank_left - df_nonties.rank_right > margin))\n",
    "    df_nonties['correct_right'] = ((df_nonties.label_r == 1) & (df_nonties.rank_right - df_nonties.rank_left > margin))\n",
    "    df_ties['correct_tie'] = (abs(df_ties.rank_left - df_ties.rank_right) < margin)\n",
    "    \n",
    "    df_nonties['correct_nontie'] = (df_nonties['correct_left'] == True) | (df_nonties['correct_right'] == True)\n",
    "    \n",
    "    errados_nontie = df_nonties[df_nonties['correct_nontie'] == False]\n",
    "    errados_tie    = df_ties[df_ties['correct_tie'] == False]\n",
    "    errados_all    = pd.concat((errados_nontie, errados_tie))\n",
    "    \n",
    "    avg_dist_nonties, _ = compute_ranking_distance(errados_nontie)\n",
    "    _, avg_dist_ties_ = compute_ranking_distance(errados_tie)\n",
    "    avg_dist_all = compute_ranking_distance_all(errados_all)\n",
    "\n",
    "    compiled_results.append({\n",
    "        'margin': margin,\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties_,\n",
    "        'avg_dist_all': avg_dist_all,\n",
    "        'std': std,\n",
    "        'min_max': min_max,\n",
    "    })\n",
    "\n",
    "df_errados_withties = pd.DataFrame(compiled_results).sort_values(['margin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1fcbd1-64fe-4b5a-8fdb-532bdec6ad5b",
   "metadata": {},
   "source": [
    "## Without ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d269741-99e5-4fae-be77-280356003655",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in glob('../outputs/saved/_noties-margin-*.pkl'):\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin = float(os.path.basename(model_result).replace('_noties-margin-', '').replace('.pt_results.pkl', ''))\n",
    "    seed = 30\n",
    "    print('Margin:', margin, '-->', model_result)\n",
    "\n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "\n",
    "    collection = []\n",
    "    for image in X_test.image_left.unique():\n",
    "        rank_image = X_test[X_test.image_left == image].iloc[0].rank_left\n",
    "        collection.append({\n",
    "                'image': image,\n",
    "                'rank': rank_image, \n",
    "                'ties': ties,\n",
    "                'margin': margin_\n",
    "            }\n",
    "        )\n",
    "    for image in X_test.image_right.unique():\n",
    "        rank_image = X_test[X_test.image_right == image].iloc[0].rank_right\n",
    "        collection.append({\n",
    "                'image': image,\n",
    "                'rank': rank_image, \n",
    "                'ties': ties,\n",
    "                'margin': margin_          \n",
    "            }\n",
    "        )\n",
    "    image_ranks = pd.DataFrame(collection).drop_duplicates()\n",
    "    std = image_ranks['rank'].std()\n",
    "    min_max = image_ranks['rank'].max() - image_ranks['rank'].min()\n",
    "    \n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = X_test[X_test.label_r != 0].copy()\n",
    "    df_ties = X_test[X_test.label_r == 0].copy()\n",
    "\n",
    "    df_nonties['correct_left'] = ((df_nonties.label_r == -1) & (df_nonties.rank_left - df_nonties.rank_right > margin))\n",
    "    df_nonties['correct_right'] = ((df_nonties.label_r == 1) & (df_nonties.rank_right - df_nonties.rank_left > margin))\n",
    "    df_ties['correct_tie'] = (abs(df_ties.rank_left - df_ties.rank_right) < margin)\n",
    "    \n",
    "    df_nonties['correct_nontie'] = (df_nonties['correct_left'] == True) | (df_nonties['correct_right'] == True)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    errados_nontie = df_nonties[df_nonties['correct_nontie'] == False]\n",
    "    errados_tie    = df_ties[df_ties['correct_tie'] == False]\n",
    "    errados_all    = pd.concat((errados_nontie, errados_tie))\n",
    "\n",
    "    # print(errados_nontie.shape, errados_tie.shape, errados_all.shape)\n",
    "    \n",
    "    avg_dist_nonties, _ = compute_ranking_distance(errados_nontie)\n",
    "    _, avg_dist_ties_ = compute_ranking_distance(errados_tie)\n",
    "    avg_dist_all = compute_ranking_distance_all(errados_all)\n",
    "\n",
    "    compiled_results.append({\n",
    "        'margin': margin,\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties_,\n",
    "        'avg_dist_all': avg_dist_all,\n",
    "        'std': std,\n",
    "        'min_max': min_max,\n",
    "    })\n",
    "\n",
    "df_errados_noties = pd.DataFrame(compiled_results).sort_values(['margin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c89df-17b7-4171-86a1-587a2433c2a9",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e218dada-acee-4f58-8b63-bb722423a876",
   "metadata": {},
   "source": [
    "### Average Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2da4a3-e21d-4d81-9744-208f231d0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3.5))\n",
    "plt.plot(df_errados_withties.margin[1:], (df_errados_withties.margin - df_errados_withties.avg_dist_all).abs()[1:], 'k', label='Trained w/ ties.')\n",
    "plt.plot(df_errados_noties.margin[1:],   (df_errados_noties.margin - df_errados_noties.avg_dist_all).abs()[1:]    , 'r', label='Trained w/o ties.', )\n",
    "#plt.plot([0, 2],   [0,2]    , 'b--', label=r'$\\gamma$', )\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('Average Absolute Error')\n",
    "plt.legend(fontsize=\"11\")\n",
    "plt.show()\n",
    "fig.savefig('error_misclassified_margin.png', dpi=fig.dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac83a0da-fed1-49f9-b6cb-f4dd8e2cced5",
   "metadata": {},
   "source": [
    "### Average Absolute Error/Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576d688-f22e-49b6-a5e8-e8b144904d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3.5))\n",
    "plt.plot(df_errados_withties.margin, (df_errados_withties.margin - df_errados_withties.avg_dist_all).abs() / (df_errados_withties['margin']+1e-14), 'k', label='Trained w/ ties.')\n",
    "plt.plot(df_errados_noties.margin,   (df_errados_noties.margin - df_errados_noties.avg_dist_all).abs()     / (df_errados_noties['margin']+1e-14)  , 'r', label='Trained w/o ties.', )\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel(r'Average Absolute Error / $\\gamma$')\n",
    "plt.ylim([0, 5])\n",
    "plt.legend(fontsize=\"11\")\n",
    "plt.show()\n",
    "fig.savefig('error_misclassified_margin.png', dpi=fig.dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ef153-e6e3-447b-9bbd-bd701481697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3.5))\n",
    "plt.plot(df_errados_withties.margin, (df_errados_withties.margin - df_errados_withties.avg_dist_nonties).abs(), 'k', label='Trained w/ ties. Non-ties ')\n",
    "plt.plot(df_errados_withties.margin, (df_errados_withties.margin - df_errados_withties.avg_dist_ties   ).abs(), 'k--',  label='Trained w/ ties. Ties', )\n",
    "\n",
    "plt.plot(df_errados_noties.margin,   (df_errados_noties.margin - df_errados_noties.avg_dist_nonties).abs(), 'r',   label='Trained w/o ties. Non-ties', )\n",
    "plt.plot(df_errados_noties.margin,   (df_errados_noties.margin - df_errados_noties.avg_dist_ties   ).abs(), 'r--',    label='Trained w/o ties. Ties', )\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel(' Asolute Error')\n",
    "plt.legend(fontsize=\"11\")\n",
    "plt.show()\n",
    "#fig.savefig('accuracy_margin.png', dpi=fig.dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42cf8c3-0d58-4f74-8ed5-cd8aade7016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3.5))\n",
    "plt.plot(df_errados_withties.margin, df_errados_withties.avg_dist_nonties, 'k', label='Trained w/ ties. Non-ties ')\n",
    "plt.plot(df_errados_withties.margin, df_errados_withties.avg_dist_ties   , 'k--',  label='Trained w/ ties. Ties', )\n",
    "\n",
    "plt.plot(df_errados_noties.margin,   df_errados_noties.avg_dist_nonties, 'r',   label='Trained w/o ties. Non-ties', )\n",
    "plt.plot(df_errados_noties.margin,   df_errados_noties.avg_dist_ties   , 'r--',    label='Trained w/o ties. Ties', )\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('Rank Difference')\n",
    "plt.legend(fontsize=\"11\")\n",
    "plt.show()\n",
    "#fig.savefig('accuracy_margin.png', dpi=fig.dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f267ec-2a8d-4d09-b98e-34dfd240e6a1",
   "metadata": {},
   "source": [
    "# Balanced ties and non-ties (0.33 for each class at test time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791eee10-a605-4f95-ba17-71f5092af98c",
   "metadata": {},
   "source": [
    "## With ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6e4fd-5903-4d7e-884c-e2b6e20736ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = glob('../outputs/saved/margin-*.pkl')\n",
    "compiled_results = []\n",
    "for model_result in model_results:\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = float(os.path.basename(model_result).replace('margin-', '').replace('.pt_results.pkl', ''))\n",
    "    seed = 30\n",
    "    print('Margin:', margin_, '-->', model_result)\n",
    "\n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "    X_test = pd.concat((X_test[(X_test.label_r == -1) | (X_test.label_r == 1)].sample(600, random_state=seed), X_test[(X_test.label_r == 0)])).reset_index().drop(columns=['index'])\n",
    "\n",
    "    # Ranking sub-network\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_)\n",
    "\n",
    "    # Ranking sub-network, without any margin on accuracy\n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "\n",
    "    # Classification sub-network\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "\n",
    "    # Rank difference\n",
    "    avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "    sum_dist_nonties, sum_dist_ties = compute_ranking_distance(X_test)\n",
    "    \n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'margin': margin_,\n",
    "        'seed': seed,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        'ranking_acc_left': nontie_left_accuracy,\n",
    "        'ranking_acc_right': nontie_right_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        'ranking_acc_left_nomargin': nontie_left_accuracy_nomargin,\n",
    "        'ranking_acc_right_nomargin': nontie_right_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'sum_dist_nonties': sum_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "        'sum_dist_ties': sum_dist_ties,\n",
    "    }\n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e80ed-24c2-4d70-b581-f3c42d50482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = results_df.sort_values(['margin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73edd6-0d9a-4e3e-a17a-21f2fdd4ba73",
   "metadata": {},
   "source": [
    "## Without ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02412aa2-8952-4135-bfc9-90916f408943",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = glob('../outputs/saved/_noties-margin-*.pkl')\n",
    "compiled_results = []\n",
    "for model_result in model_results:\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = float(os.path.basename(model_result).replace('_noties-margin-', '').replace('.pt_results.pkl', ''))\n",
    "    seed = 30\n",
    "    print('Margin:', margin_, '-->', model_result)\n",
    "\n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "    X_test = pd.concat((X_test[(X_test.label_r == -1) | (X_test.label_r == 1)].sample(600, random_state=seed), X_test[(X_test.label_r == 0)])).reset_index().drop(columns=['index'])\n",
    "\n",
    "    \n",
    "    # Ranking sub-network\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_)\n",
    "\n",
    "    # Ranking sub-network, without any margin on accuracy\n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "\n",
    "    # Classification sub-network\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "\n",
    "    # Rank difference\n",
    "    avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "    sum_dist_nonties, sum_dist_ties = compute_ranking_distance(X_test)\n",
    "    \n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'margin': margin_,\n",
    "        'seed': seed,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        'ranking_acc_left': nontie_left_accuracy,\n",
    "        'ranking_acc_right': nontie_right_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        'ranking_acc_left_nomargin': nontie_left_accuracy_nomargin,\n",
    "        'ranking_acc_right_nomargin': nontie_right_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'sum_dist_nonties': sum_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "        'sum_dist_ties': sum_dist_ties,\n",
    "    }\n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5df504-bb42-46f0-854b-fa2075a7c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = results_df.sort_values(['margin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e8c4f8-2ae2-4f30-be41-9a3c8cd513ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3.5))\n",
    "plt.plot(aa.margin, aa.ranking_acc, 'k',                    label='Trained w/ ties. ')\n",
    "#plt.plot(df_withties.margin, df_withties.ranking_acc_nonties_nomargin, 'k--', label='Trained w/ ties. Acc. w/o margin', )\n",
    "plt.plot(bb.margin, bb.ranking_acc, 'r',                        label='Trained w/o ties. ', )\n",
    "#plt.plot(df_noties.margin, df_noties.ranking_acc_nonties_nomargin, 'r--',     label='Trained w/o ties. Acc. w/o margin', )\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(fontsize=\"11\")\n",
    "plt.show()\n",
    "fig.savefig('accuracy_margin.png', dpi=fig.dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af1ab96-e9e1-43a6-afc1-ffa8222c5d3a",
   "metadata": {},
   "source": [
    "# Distribution of Ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c70a53-985b-4c96-b4d9-e8787c4b606d",
   "metadata": {},
   "source": [
    "## Margin=0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def6709-facc-4dc8-8d5d-0336a332ce6b",
   "metadata": {},
   "source": [
    "### Trained without ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036301e6-0a5f-4219-9006-3af31417f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = glob('../outputs/saved/_noties-margin-0.7*.pkl')[0]\n",
    "print('Loading model:', model_result)\n",
    "df_noties = pd.read_pickle(model_result)\n",
    "df_noties['rank_diff'] = (df_noties.rank_left - df_noties.rank_right)#.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd375c25-ebbe-4edf-bb4b-e373e700a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,1.5))\n",
    "plt.hist(df_noties.rank_diff, 25, density=1)\n",
    "plt.axvline(x=.7, color = 'k', label=r'$\\gamma$')\n",
    "plt.title(r'Rank difference density ($\\gamma$=.7). All data')\n",
    "#plt.xlim([0, 10])\n",
    "#plt.ylim([0, 1.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27cb17d-080e-48de-9b23-e31eb070a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,1.5))\n",
    "plt.hist(df_noties[df_noties.label_r == 0].rank_diff, 25, density=1, color='green', alpha=1, label='Ties')\n",
    "plt.hist(df_noties[df_noties.label_r != 0].rank_diff, 25, density=1, color='red', alpha=0.7, label='Non-ties')\n",
    "plt.axvline(x=.7, color='k', label=r'$\\gamma$=0.7')\n",
    "plt.axvline(x=-.7, color='k', label=r'$\\gamma$=0.7')\n",
    "plt.legend(fontsize=\"9\")\n",
    "#plt.xlim([0, 6])\n",
    "#plt.ylim([0, 1.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99462047-c56b-4d8e-96df-51e72ff98e10",
   "metadata": {},
   "source": [
    "### Trained with ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35de416-01f5-453c-9cae-f667b91c8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = glob('../outputs/saved/margin-0.7*.pkl')[0]\n",
    "print('Loading model:', model_result)\n",
    "df_ties = pd.read_pickle(model_result)\n",
    "df_ties['rank_diff'] = (df_ties.rank_left - df_ties.rank_right)#.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329299e-5e31-4934-af1a-ab3f4e220482",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,1.5))\n",
    "plt.hist(df_ties.rank_diff, 25, density=1)\n",
    "plt.axvline(x=.7, color='k', label=r'$\\gamma$')\n",
    "plt.title(r'Rank difference density ($\\gamma$=.7). All data')\n",
    "#plt.xlim([0, 10])\n",
    "#plt.ylim([0, 1.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590285f-b7da-4a0e-baf8-455155db9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,1.5))\n",
    "plt.hist(df_ties[df_ties.label_r == 0].rank_diff, 25, density=1, color='green', alpha=1, label='Ties')\n",
    "plt.hist(df_ties[df_ties.label_r != 0].rank_diff, 25, density=1, color='red', alpha=0.7, label='Non-ties')\n",
    "plt.axvline(x=.7, color='k', label=r'$\\gamma$=0.7')\n",
    "plt.axvline(x=-.7, color='k', label=r'$\\gamma$=0.7')\n",
    "plt.legend(fontsize=\"9\")\n",
    "plt.xlabel('Absolute rank difference')\n",
    "plt.ylabel('Density')\n",
    "#plt.xlim([0, 6])\n",
    "#plt.ylim([0, 1.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b2c4a-cf54-4bdd-920c-7ab71f56212a",
   "metadata": {},
   "source": [
    "### Comparison ties vs. non-ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46076271-d095-4aba-8f07-af2f058c55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(5,3.5))\n",
    "axs[0].hist(df_noties[df_noties.label_r == 0].rank_diff,                             bins=np.arange(-6., 6.5, 0.3), color='blue',   alpha=1,   label='Tie',   weights=np.ones_like(df_noties[df_noties.label_r == 0].rank_diff) / len(df_noties[df_noties.label_r == 0].rank_diff))\n",
    "axs[0].hist(df_noties[(df_noties.label_r != 0) & (df_noties.label_r > 0)].rank_diff, bins=np.arange(-6., 6.5, 0.3), color='purple', alpha=0.7, label='Left',  weights=np.ones_like(df_noties[(df_noties.label_r != 0) & (df_noties.label_r > 0)].rank_diff) / len(df_noties[(df_noties.label_r != 0) & (df_noties.label_r > 0)].rank_diff))\n",
    "axs[0].hist(df_noties[(df_noties.label_r != 0) & (df_noties.label_r < 0)].rank_diff, bins=np.arange(-6., 6.5, 0.3), color='orange', alpha=0.7, label='Right', weights=np.ones_like(df_noties[(df_noties.label_r != 0) & (df_noties.label_r < 0)].rank_diff) / len(df_noties[(df_noties.label_r != 0) & (df_noties.label_r < 0)].rank_diff))\n",
    "axs[0].axvline(x=.7, color='k', label=r'$|\\gamma|$=0.7')\n",
    "axs[0].axvline(x=-.7, color='k', )#label=r'$\\gamma$=0.7')\n",
    "axs[0].legend(fontsize=\"9\")\n",
    "axs[0].axis(ymin=0, ymax=.2, xmin=-6,xmax=6), \n",
    "axs[0].set_title('Trained w/o Ties', fontsize=\"11\")\n",
    "\n",
    "axs[1].hist(df_ties[df_ties.label_r == 0].rank_diff,                           bins=np.arange(-6., 6.5, 0.3), color='blue',   alpha=1,   label='Tie',   weights=np.ones_like(df_ties[df_ties.label_r == 0].rank_diff) / len(df_ties[df_ties.label_r == 0].rank_diff))\n",
    "axs[1].hist(df_ties[(df_ties.label_r != 0) & (df_ties.label_r > 0)].rank_diff, bins=np.arange(-6., 6.5, 0.3), color='purple', alpha=0.7, label='Left',  weights=np.ones_like(df_ties[(df_ties.label_r != 0) & (df_ties.label_r > 0)].rank_diff) / len(df_ties[(df_ties.label_r != 0) & (df_ties.label_r > 0)].rank_diff))\n",
    "axs[1].hist(df_ties[(df_ties.label_r != 0) & (df_ties.label_r < 0)].rank_diff, bins=np.arange(-6., 6.5, 0.3), color='orange', alpha=0.7, label='Right', weights=np.ones_like(df_ties[(df_ties.label_r != 0) & (df_ties.label_r < 0)].rank_diff) / len(df_ties[(df_ties.label_r != 0) & (df_ties.label_r < 0)].rank_diff))\n",
    "axs[1].axvline(x=.7, color='k', label=r'$|\\gamma|$=0.7')\n",
    "axs[1].axvline(x=-.7, color='k', )#label=r'$\\gamma$=0.7')\n",
    "#axs[1].legend(fontsize=\"9\")\n",
    "axs[1].axis(ymin=0, ymax=.2, xmin=-6,xmax=6)\n",
    "axs[1].set_title('Trained w/ Ties', fontsize=\"11\")\n",
    "\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Rank difference', ylabel='Relative Frequency')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.savefig('rank_difference_distribution.png', dpi=fig.dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445cb061-390f-4c39-92c4-54164d3bcc4d",
   "metadata": {},
   "source": [
    "## Margin=1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf25530c-ecac-459d-98d5-1f0ddeab94db",
   "metadata": {},
   "source": [
    "### Trained without ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b348c3-a709-4691-b285-c17e425aeded",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = glob('../outputs/saved/_noties-margin-1.5*.pkl')[0]\n",
    "print('Loading model:', model_result)\n",
    "df_noties = pd.read_pickle(model_result)\n",
    "df_noties['rank_diff'] = (df_noties.rank_left - df_noties.rank_right)#.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd2271-063d-4867-965b-85a9c726ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,1.5))\n",
    "plt.hist(df_noties.rank_diff, 25, density=1)\n",
    "plt.axvline(x=.7, color = 'k', label=r'$\\gamma$')\n",
    "plt.title(r'Rank difference density ($\\gamma$=.7). All data')\n",
    "#plt.xlim([0, 10])\n",
    "#plt.ylim([0, 1.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b49e2-8fa4-4ce3-b053-0093efec3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,1.5))\n",
    "plt.hist(df_noties[df_noties.label_r == 0].rank_diff, 25, density=1, color='green', alpha=1, label='Ties')\n",
    "plt.hist(df_noties[df_noties.label_r != 0].rank_diff, 25, density=1, color='red', alpha=0.7, label='Non-ties')\n",
    "plt.axvline(x=1.5, color='k', label=r'$\\gamma$=0.7')\n",
    "plt.axvline(x=-1.5, color='k', label=r'$\\gamma$=0.7')\n",
    "plt.legend(fontsize=\"9\")\n",
    "#plt.xlim([0, 6])\n",
    "#plt.ylim([0, 1.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe8e0a-28ad-482e-9dbf-914d8f4538a9",
   "metadata": {},
   "source": [
    "### Trained with ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd9403f-c04f-41b8-b77d-8ccd6d5ba38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = glob('../outputs/saved/margin-1.5*.pkl')[0]\n",
    "print('Loading model:', model_result)\n",
    "df_ties = pd.read_pickle(model_result)\n",
    "df_ties['rank_diff'] = (df_ties.rank_left - df_ties.rank_right)#.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89898942-658d-40b1-8f74-17b0e36b6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,1.5))\n",
    "plt.hist(df_ties.rank_diff, 25, density=1)\n",
    "plt.axvline(x=.7, color='k', label=r'$\\gamma$')\n",
    "plt.title(r'Rank difference density ($\\gamma$=.7). All data')\n",
    "#plt.xlim([0, 10])\n",
    "#plt.ylim([0, 1.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99e702-d994-4576-82ed-5b4b2fc53ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,1.5))\n",
    "plt.hist(df_ties[df_ties.label_r == 0].rank_diff, 25, density=1, color='green', alpha=1, label='Ties')\n",
    "plt.hist(df_ties[df_ties.label_r != 0].rank_diff, 25, density=1, color='red', alpha=0.7, label='Non-ties')\n",
    "plt.axvline(x=1.5, color='k', label=r'$\\gamma$=0.7')\n",
    "plt.axvline(x=-1.5, color='k', label=r'$\\gamma$=0.7')\n",
    "plt.legend(fontsize=\"9\")\n",
    "plt.xlabel('Absolute rank difference')\n",
    "plt.ylabel('Density')\n",
    "#plt.xlim([0, 6])\n",
    "#plt.ylim([0, 1.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae274232-b5f9-4e38-9bad-a323f5d0c26c",
   "metadata": {},
   "source": [
    "### Comparison ties vs. non-ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222c85d-23df-451f-82fb-20a401a5d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(5,3.5))\n",
    "axs[0].hist(df_noties[df_noties.label_r == 0].rank_diff, 25, density=1, color='green', alpha=1, label='Ties')\n",
    "axs[0].hist(df_noties[(df_noties.label_r != 0) & (df_noties.label_r > 0)].rank_diff, 25, density=1, color='red', alpha=0.6, label='Non-ties')\n",
    "axs[0].hist(df_noties[(df_noties.label_r != 0) & (df_noties.label_r < 0)].rank_diff, 25, density=1, color='orange', alpha=0.6, label='Non-ties')\n",
    "axs[0].axvline(x=1.5, color='k', label=r'$\\gamma$=0.7')\n",
    "axs[0].axvline(x=-1.5, color='k', label=r'$\\gamma$=0.7')\n",
    "axs[0].legend(fontsize=\"9\")\n",
    "axs[0].axis(ymin=0, ymax=.57, xmin=-10,xmax=10), \n",
    "axs[0].set_title('Trained w/o Ties', fontsize=\"11\")\n",
    "\n",
    "axs[1].hist(df_ties[df_ties.label_r == 0].rank_diff, 25, density=1, color='green', alpha=1, label='Ties')\n",
    "axs[1].hist(df_ties[(df_ties.label_r != 0) & (df_ties.label_r > 0)].rank_diff, 25, density=1, color='red', alpha=0.6, label='Non-ties')\n",
    "axs[1].hist(df_ties[(df_ties.label_r != 0) & (df_ties.label_r < 0)].rank_diff, 25, density=1, color='orange', alpha=0.6, label='Non-ties, ')\n",
    "axs[1].axvline(x=1.5, color='k', label=r'$\\gamma$=0.7')\n",
    "axs[1].axvline(x=-1.5, color='k', label=r'$\\gamma$=0.7')\n",
    "axs[1].legend(fontsize=\"9\")\n",
    "axs[1].axis(ymin=0, ymax=.57, xmin=-10,xmax=10)\n",
    "axs[1].set_title('Trained w/ Ties', fontsize=\"11\")\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Absolute rank difference', ylabel='Density')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.savefig('rank_difference_distribution.png', dpi=fig.dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f043b693-1fe2-49db-913f-9937b347d0c3",
   "metadata": {},
   "source": [
    "# Rank score between including and not including ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6e5d3-9cae-498a-9601-038ae714cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in ['../outputs/saved/_noties-margin-0.7.pt_results.pkl', '../outputs/saved/margin-0.7.pt_results.pkl']:\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = 0.7\n",
    "    seed = 30\n",
    "    print('Margin:', margin_, '-->', model_result)\n",
    "    if 'noties' in model_result:\n",
    "        ties = True\n",
    "    else:\n",
    "        ties = False\n",
    "\n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "    # Ranking sub-network\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_)\n",
    "\n",
    "    # Ranking sub-network, without any margin on accuracy\n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "\n",
    "    # Classification sub-network\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "\n",
    "    # Rank difference\n",
    "    avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'ties': ties,\n",
    "        'margin': margin_,\n",
    "        'seed': seed,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        'ranking_acc_left': nontie_left_accuracy,\n",
    "        'ranking_acc_right': nontie_right_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        'ranking_acc_left_nomargin': nontie_left_accuracy_nomargin,\n",
    "        'ranking_acc_right_nomargin': nontie_right_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "    }\n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18251d8c-622d-4749-ac4f-2e0ac07118ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2cb5f9-a809-4eb0-8433-e0a7f9b78d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in ['../outputs/saved/_noties-margin-0.7.pt_results.pkl', '../outputs/saved/margin-0.7.pt_results.pkl']:\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = 0.7\n",
    "    seed = 30\n",
    "    print('Margin:', margin_, '-->', model_result)\n",
    "    if 'noties' in model_result:\n",
    "        ties = True\n",
    "    else:\n",
    "        ties = False\n",
    "\n",
    "    collection = []\n",
    "    for image in df.image_left.unique():\n",
    "        rank_image = df[df.image_left == image].iloc[0].rank_left\n",
    "        collection.append(\n",
    "            {\n",
    "                'image': image,\n",
    "                'rank': rank_image, \n",
    "                'ties': ties\n",
    "            }\n",
    "        )\n",
    "    for image in df.image_right.unique():\n",
    "        rank_image = df[df.image_right == image].iloc[0].rank_right\n",
    "        collection.append(\n",
    "            {\n",
    "                'image': image,\n",
    "                'rank': rank_image, \n",
    "                'ties': ties           \n",
    "            }\n",
    "        )\n",
    "\n",
    "    image_ranks = pd.DataFrame(collection).drop_duplicates()\n",
    "\n",
    "    compiled_results.append(image_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76665bfb-c6d6-4e62-b343-b18ae38ac131",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a5d6db-3133-4322-825a-4471ebbde867",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addab75a-e81f-4aa4-8f87-7b610d3ec662",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['diff'] = all_df.groupby(by=['image'])['rank'].diff()\n",
    "all_df['diff'] = all_df['diff'].abs()\n",
    "all_df['relative_change'] = (all_df['diff'] / all_df['rank']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07e2db-69a4-47c3-b850-db5975005678",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[all_df['diff'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d7e94b-1f60-4d5a-916b-da3af80a838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.hist(all_df[all_df['diff'].notna()]['diff'], 50, color='green', alpha=1, label='Ties')\n",
    "#plt.legend()\n",
    "#plt.title(r'aaa')\n",
    "plt.xlabel('Absolute difference')\n",
    "plt.ylabel('# of images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd21ab0-7edc-45db-8a80-8cdac2a4699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "\n",
    "n,x,_ = plt.hist(all_df[all_df['ties'] == True]['rank'], 50, density=True, color='red', alpha=1, histtype='step', label='With Ties')\n",
    "#bin_centers = 0.5*(x[1:]+x[:-1])\n",
    "#plt.plot(bin_centers, n, 'red') ## using bin_centers rather than edges\n",
    "n,x,_ = plt.hist(all_df[all_df['ties'] == False]['rank'], 50, density=True, color='blue', alpha=1, histtype='step', label='Without ties')\n",
    "#bin_centers = 0.5*(x[1:]+x[:-1])\n",
    "#plt.plot(bin_centers, n, 'blue') \n",
    "plt.legend()\n",
    "#plt.title(r'aaa')\n",
    "plt.xlabel('Image rank distribution')\n",
    "plt.ylabel('Density ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b2512-95f3-400c-9afa-5d50be91f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[all_df['diff'].notna()].relative_change.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007c3bea-5d0d-497d-825e-516728a9819b",
   "metadata": {},
   "source": [
    "# Rank distribution per margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2599ad-d716-4717-b103-847e2bc38a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in glob('../outputs/saved/margin-*.pkl'):\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = float(os.path.basename(model_result).replace('margin-', '').replace('.pt_results.pkl', ''))\n",
    "    seed = 30\n",
    "    print('Margin:', margin_, '-->', model_result)\n",
    "    if 'noties' in model_result:\n",
    "        ties = True\n",
    "    else:\n",
    "        ties = False\n",
    "\n",
    "    collection = []\n",
    "    for image in df.image_left.unique():\n",
    "        rank_image = df[df.image_left == image].iloc[0].rank_left\n",
    "        collection.append({\n",
    "                'image': image,\n",
    "                'rank': rank_image, \n",
    "                'ties': ties,\n",
    "                'margin': margin_\n",
    "            }\n",
    "        )\n",
    "    for image in df.image_right.unique():\n",
    "        rank_image = df[df.image_right == image].iloc[0].rank_right\n",
    "        collection.append({\n",
    "                'image': image,\n",
    "                'rank': rank_image, \n",
    "                'ties': ties,\n",
    "                'margin': margin_          \n",
    "            }\n",
    "        )\n",
    "\n",
    "    image_ranks = pd.DataFrame(collection).drop_duplicates()\n",
    "\n",
    "    compiled_results.append(image_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2513bf-aeb3-4959-ac8b-2203ab3cb411",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c2c3e-db31-4f67-a843-ba321247de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for margin in sorted([ 0.8, 0.7, 0.6, 1.4, 0.3, 1.2, 1.0, 1.5, 1.3, 0.2, 0.0, 1.9, 2.0, 0.9, 1.7, 0.5, 1.8, 1.6, 0.1, 0.4, 1.1,]):\n",
    "    n,x,_ = plt.hist(all_df[all_df['margin'] == margin]['rank'], 50, density=True, alpha=1, histtype='step', label='{}'.format(margin))\n",
    "#bin_centers = 0.5*(x[1:]+x[:-1])\n",
    "#plt.plot(bin_centers, n, 'red') ## using bin_centers rather than edges\n",
    "#n,x,_ = plt.hist(all_df[all_df['ties'] == False]['rank'], 50, density=True, color='blue', alpha=1, histtype='step', label='Without ties')\n",
    "#bin_centers = 0.5*(x[1:]+x[:-1])\n",
    "#plt.plot(bin_centers, n, 'blue') \n",
    "plt.legend()\n",
    "#plt.title(r'aaa')\n",
    "plt.xlabel('Image rank distribution')\n",
    "plt.ylabel('Density ')\n",
    "plt.xlim(-5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d5d69-0dd9-4097-969d-296071bfe586",
   "metadata": {},
   "source": [
    "# Different Tie & Non-tie margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b2896-f537-4ce7-9fa5-546962c46214",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob('../outputs/saved/ties_margin_*.pkl') + glob('../outputs/saved/margin-0.7*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc803744-8702-4b49-8527-08d896345131",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in glob('../outputs/saved/ties_margin_*.pkl') + glob('../outputs/saved/margin-0.7*.pkl'):\n",
    "    df = pd.read_pickle(model_result)\n",
    "    seed = 30\n",
    "    \n",
    "    if 'colorful-firefly-666' in model_result:\n",
    "        margin_nonties = 0.7\n",
    "        margin_ties = 1.4\n",
    "    elif 'spring-plasma-667' in model_result:\n",
    "        margin_nonties = 0.7\n",
    "        margin_ties = 1.0\n",
    "    elif 'daily-sky-671' in model_result:\n",
    "        margin_nonties = 1.0\n",
    "        margin_ties = 0.7\n",
    "    elif 'vibrant-pond-670' in model_result:\n",
    "        margin_nonties = 1.4\n",
    "        margin_ties = 0.7\n",
    "    elif 'margin-0.7' in model_result:\n",
    "        margin_nonties = 0.7\n",
    "        margin_ties = 0.7\n",
    "        \n",
    "    print('Margin Nonties:', margin_nonties, ' / Margin Ties:', margin_ties, '-->', model_result)\n",
    "\n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "\n",
    "    # Ranking sub-network\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_ties)\n",
    "\n",
    "    # Ranking sub-network, without any margin on accuracy\n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "\n",
    "    # Classification sub-network\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "\n",
    "    # Rank difference\n",
    "    avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "    sum_dist_nonties, sum_dist_ties = compute_ranking_distance_sum(X_test)\n",
    "    \n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'margin_ties': margin_ties,\n",
    "        'margin_nonties': margin_nonties,\n",
    "        'seed': seed,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'sum_dist_nonties': sum_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "        'sum_dist_ties': sum_dist_ties,\n",
    "    }\n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results).sort_values(by=['margin_ties', 'margin_nonties'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3a9e6-3aca-4511-af6c-6dd54b44cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429fe98-b915-411d-92e6-dd040043f75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d17d6-9077-4ca0-ab4c-3c339fa88591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc9b2d-aef8-4acc-857a-89dab225c405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0243ea-26bd-4118-875f-800c667b6a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c10512-8208-40fa-8853-7c11df5c2c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ae77a-0555-4988-9ae6-c93a0bda79b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e0180-2078-4f64-8a66-5135467be78a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
