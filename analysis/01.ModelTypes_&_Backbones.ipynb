{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2c189-8f29-4e8e-a8f6-a68e62dd0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37951da9-3e54-44e6-a2b9-47f1ee745ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f98a8-8dc3-4d6b-ae14-4e56077657dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('font',**{'family':'serif',\n",
    "             'serif':['Times New Roman'],\n",
    "             'size': 12,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87358ad-aaf8-454f-8f8d-bca1df6bebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_accuracy(df_, margin=0):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "    df_ties = df_[df_.label_r == 0]\n",
    "\n",
    "    # Split non ties per their outcome (left and right)\n",
    "    df_nonties_left = df_nonties[(df_nonties.label_r == -1)]\n",
    "    df_nonties_right = df_nonties[(df_nonties.label_r == 1)]\n",
    "\n",
    "    # Non-ties accuracy\n",
    "    correct_left = ((df_nonties.label_r == -1) & (df_nonties.rank_left - df_nonties.rank_right > margin)).sum()\n",
    "    correct_right = ((df_nonties.label_r == 1) & (df_nonties.rank_right - df_nonties.rank_left > margin)).sum()\n",
    "\n",
    "    nontie_left_accuracy = correct_left / (df_nonties.label_r == -1).sum()\n",
    "    nontie_right_accuracy = correct_right / (df_nonties.label_r == 1).sum()\n",
    "    nontie_accuracy = (correct_left + correct_right ) / df_nonties.shape[0]\n",
    "    \n",
    "    # Ties accuracy\n",
    "    tie_accuracy = (abs(df_ties.rank_left - df_ties.rank_right) < margin).sum() / df_ties.shape[0]\n",
    "\n",
    "    # Overall accuracy\n",
    "    overall_accuracy = X_test[((df_.label_r == -1) & (df_.rank_left - df_.rank_right > margin)) |\n",
    "                              ((df_.label_r ==  1) & (df_.rank_right - df_.rank_left > margin)) |\n",
    "                              ((df_.label_r ==  0) & (abs(df_.rank_left - df_.rank_right) < margin))].shape[0] / df_.shape[0]\n",
    "    \n",
    "    return nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf58ec2a-00b1-47cd-9335-ddc4bfb0602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_accuracy_nomargin(df_,):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "\n",
    "    # Split non ties per their outcome (left and right)\n",
    "    df_nonties_left = df_nonties[(df_nonties.label_r == -1)]\n",
    "    df_nonties_right = df_nonties[(df_nonties.label_r == 1)]\n",
    "\n",
    "    # Non-ties accuracy\n",
    "    correct_left = ((df_nonties.label_r == -1) & (df_nonties.rank_left - df_nonties.rank_right > 0)).sum()\n",
    "    correct_right = ((df_nonties.label_r == 1) & (df_nonties.rank_right - df_nonties.rank_left > 0)).sum()\n",
    "\n",
    "    nontie_left_accuracy = correct_left / (df_nonties.label_r == -1).sum()\n",
    "    nontie_right_accuracy = correct_right / (df_nonties.label_r == 1).sum()\n",
    "    nontie_accuracy = (correct_left + correct_right ) / df_nonties.shape[0]\n",
    "\n",
    "    return nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b4fcc-a55f-4bab-b166-1d1684440b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_distance(df_):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "    df_ties = df_[df_.label_r == 0]\n",
    "\n",
    "    # Distance between non-ties\n",
    "    avg_dist_nonties = abs(df_nonties.rank_left - df_nonties.rank_right).mean()\n",
    "    \n",
    "    # Distance between ties\n",
    "    avg_dist_ties = abs(df_ties.rank_left - df_ties.rank_right).mean()\n",
    "    \n",
    "    return avg_dist_nonties, avg_dist_ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72fe07-7643-490f-9ee9-7757247cec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(df_):\n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "    if 'logits_0' in df_.columns:\n",
    "        col1_values = df_['logits_l'].values\n",
    "        col2_values = df_['logits_0'].values\n",
    "        col3_values = df_['logits_r'].values\n",
    "            \n",
    "        probabilities = np.apply_along_axis(softmax, axis=1, arr=np.column_stack((col1_values, col2_values, col3_values)))\n",
    "        max_indices = np.argmax(probabilities, axis=1)\n",
    "        # Convert the probabilities back to a DataFrame with appropriate column names\n",
    "        softmax_df = pd.DataFrame(probabilities, columns=['softmax_logit_l', 'softmax_logit_0', 'softmax_logit_r'])\n",
    "        max_index_df = pd.DataFrame({'class_predicted': max_indices})\n",
    "        # Concatenate the new DataFrame with the original DataFrame if needed\n",
    "        result_df = pd.concat([df_.reset_index(drop=True), softmax_df, max_index_df], axis=1,)\n",
    "    \n",
    "        all_accuracy = (result_df.class_predicted == result_df.label_c).sum() / result_df.shape[0]\n",
    "        tie_accuracy = (result_df[result_df.label_c == 1].class_predicted == result_df[result_df.label_c == 1].label_c).sum() / result_df.shape[0]\n",
    "        nontie_accuracy = (result_df[result_df.label_c != 1].class_predicted == result_df[result_df.label_c != 1].label_c).sum() / result_df.shape[0]\n",
    "    \n",
    "    # Without ties\n",
    "    else:\n",
    "        col1_values = df_['logits_l'].values\n",
    "        col3_values = df_['logits_r'].values\n",
    "            \n",
    "        probabilities = np.apply_along_axis(softmax, axis=1, arr=np.column_stack((col1_values, col3_values)))\n",
    "        max_indices = np.argmax(probabilities, axis=1)\n",
    "        # Convert the probabilities back to a DataFrame with appropriate column names\n",
    "        softmax_df = pd.DataFrame(probabilities, columns=['softmax_logit_l', 'softmax_logit_r'])\n",
    "        max_index_df = pd.DataFrame({'class_predicted': max_indices})\n",
    "        # Concatenate the new DataFrame with the original DataFrame if needed\n",
    "        result_df = pd.concat([df_.reset_index(drop=True), softmax_df, max_index_df], axis=1,)\n",
    "    \n",
    "        all_accuracy = (result_df.class_predicted == result_df.label_c).sum() / result_df.shape[0]\n",
    "        tie_accuracy = 0\n",
    "        nontie_accuracy = all_accuracy\n",
    "        \n",
    "    return all_accuracy, tie_accuracy, nontie_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8908fd94-9164-429d-ac61-46b4e9760ceb",
   "metadata": {},
   "source": [
    "# Test backbones. Real Data & Real+Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c1d4e-50bf-44e7-a087-55ece8e01d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in [\n",
    "    '../outputs/saved/backbone_alex_alex_ber.pt_results.pkl',\n",
    "    '../outputs/saved/backbone_vgg_vgg_ber.pt_results.pkl',\n",
    "    '../outputs/saved/backbone_resnet_resnet_ber.pt_results.pkl',\n",
    "    '../outputs/saved/backbone_deit_deit_ber.pt_results.pkl',\n",
    "    '../outputs/saved/backbone_alex_syn+ber_alex_syn+ber.pt_results.pkl',\n",
    "    '../outputs/saved/backbone_vgg_syn+ber_vgg_syn+ber.pt_results.pkl',\n",
    "    '../outputs/saved/backbone_resnet_syn+ber_resnet_syn+ber.pt_results.pkl',\n",
    "    '../outputs/saved/backbone_deit_syn+ber_deit_syn+ber.pt_results.pkl',\n",
    "    ]:\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = 1\n",
    "    seed = 30\n",
    "    if 'alex' in model_result:\n",
    "        model = 'alex'\n",
    "    elif 'vgg' in model_result:\n",
    "        model = 'vgg'\n",
    "    elif 'resnet' in model_result:\n",
    "        model = 'resnet'\n",
    "    elif 'deit' in model_result:\n",
    "        model = 'deit'\n",
    "    else:\n",
    "        print('Could not find model name')\n",
    "        break\n",
    "\n",
    "    \n",
    "    if 'syn+' in model_result:\n",
    "        with_synthetic = True\n",
    "    else:\n",
    "        with_synthetic = False\n",
    "    \n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "    \n",
    "    # Ranking sub-network\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_)\n",
    "    \n",
    "    # Ranking sub-network, without any margin on accuracy\n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "    \n",
    "    # Classification sub-network\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "    \n",
    "    # Rank difference\n",
    "    avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'model': model,\n",
    "        'margin': margin_,\n",
    "        'seed': seed,\n",
    "        'with_synthetic': with_synthetic,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        'ranking_acc_left': nontie_left_accuracy,\n",
    "        'ranking_acc_right': nontie_right_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        'ranking_acc_left_nomargin': nontie_left_accuracy_nomargin,\n",
    "        'ranking_acc_right_nomargin': nontie_right_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "    }\n",
    "    \n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d25516-65a3-4ce8-9724-35dfa287a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[['model', 'with_synthetic', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37ebaa-2572-44e4-80a0-a3cd39b9d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['model'] = results_df['model'].str.replace('vgg', 'VGG')\n",
    "results_df['model'] = results_df['model'].str.replace('alex', 'AlexNet')\n",
    "results_df['model'] = results_df['model'].str.replace('deit', 'DeiT Small')\n",
    "results_df['model'] = results_df['model'].str.replace('resnet', 'ResNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b38193-6e01-4a86-a343-2d1a4724098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df[['with_synthetic', 'model', 'ranking_acc_nonties_nomargin']].round(3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9aacf1-e4c4-4da1-889d-2cd887f0a94e",
   "metadata": {},
   "source": [
    "# Model Type: RCNN, SSCNN & RSSCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ad075-b56d-4002-bc2e-7a4e0f52c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in [\n",
    "    '../outputs/saved/model_types/rcnn.pt_results.pkl',\n",
    "    '../outputs/saved/model_types/sscnn.pt_results.pkl',\n",
    "    '../outputs/saved/model_types/rsscnn.pt_results.pkl',\n",
    "    ]:\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = 1\n",
    "    seed = 30\n",
    "    if 'rcnn' in model_result:\n",
    "        model = 'rcnn'\n",
    "    elif 'rsscnn' in model_result:\n",
    "        model = 'rsscnn'\n",
    "    elif 'sscnn' in model_result:\n",
    "        model = 'sscnn'\n",
    "    else:\n",
    "        print('Could not find model name')\n",
    "        break\n",
    "    \n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = 0, 0, 0, 0, 0 \n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = 0, 0, 0\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = 0, 0, 0\n",
    "    avg_dist_nonties, avg_dist_ties = 0, 0\n",
    "        \n",
    "    if model == 'rcnn' or model == 'rsscnn':\n",
    "        # Ranking sub-network\n",
    "        nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_)\n",
    "    \n",
    "        # Ranking sub-network, without any margin on accuracy\n",
    "        nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "\n",
    "        # Rank difference\n",
    "        avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "        \n",
    "    if model == 'sscnn' or model == 'rsscnn':    \n",
    "        # Classification sub-network\n",
    "        c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'model': model,\n",
    "        'margin': margin_,\n",
    "        'seed': seed,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        'ranking_acc_left': nontie_left_accuracy,\n",
    "        'ranking_acc_right': nontie_right_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        'ranking_acc_left_nomargin': nontie_left_accuracy_nomargin,\n",
    "        'ranking_acc_right_nomargin': nontie_right_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "    }\n",
    "    \n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e470b9e-5c9a-4dba-98ed-00ddee181b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a24985-4555-42ea-9f53-364af84e3e30",
   "metadata": {},
   "source": [
    "# Synthetic-only, Model Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc51535-70c8-4106-93be-b1efa58ded08",
   "metadata": {},
   "source": [
    "## RCNN & SSCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b7ed02-eb0b-423b-9246-eead9d7c329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in glob('../outputs/saved/synth_*.pkl'):\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = 1\n",
    "    seed = 30\n",
    "    if 'rcnn' in model_result:\n",
    "        model = 'rcnn'\n",
    "    elif 'rsscnn' in model_result:\n",
    "        model = 'rsscnn'\n",
    "    elif 'sscnn' in model_result:\n",
    "        model = 'sscnn'\n",
    "    else:\n",
    "        print('Could not find model name')\n",
    "        break\n",
    "    \n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = 0, 0, 0, 0, 0 \n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = 0, 0, 0\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = 0, 0, 0\n",
    "    avg_dist_nonties, avg_dist_ties = 0, 0\n",
    "        \n",
    "    if model == 'rcnn' or model == 'rsscnn':\n",
    "        # Ranking sub-network\n",
    "        nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_)\n",
    "    \n",
    "        # Ranking sub-network, without any margin on accuracy\n",
    "        nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "\n",
    "        # Rank difference\n",
    "        avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "        \n",
    "    if model == 'sscnn' or model == 'rsscnn':    \n",
    "        # Classification sub-network\n",
    "        c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'model': model,\n",
    "        'margin': margin_,\n",
    "        'seed': seed,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        'ranking_acc_left': nontie_left_accuracy,\n",
    "        'ranking_acc_right': nontie_right_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        'ranking_acc_left_nomargin': nontie_left_accuracy_nomargin,\n",
    "        'ranking_acc_right_nomargin': nontie_right_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "    }\n",
    "    \n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1bb929-7efe-4ed0-8364-4efefa6d80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6798f5-7ee4-4dea-83a8-6db1bcbbdf94",
   "metadata": {},
   "source": [
    "## RSSCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0c786-44fb-4f82-b941-713f6a88b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in glob('../outputs/saved/syn_rsscnn_synthetic_vgg_rsscnn*.pkl'):\n",
    "    df = pd.read_pickle(model_result)\n",
    "    margin_ = 1\n",
    "    seed = 30\n",
    "    if 'rcnn' in model_result:\n",
    "        model = 'rcnn'\n",
    "    elif 'rsscnn' in model_result:\n",
    "        model = 'rsscnn'\n",
    "    elif 'sscnn' in model_result:\n",
    "        model = 'sscnn'\n",
    "    else:\n",
    "        print('Could not find model name')\n",
    "        break\n",
    "    \n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = 0, 0, 0, 0, 0 \n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = 0, 0, 0\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = 0, 0, 0\n",
    "    avg_dist_nonties, avg_dist_ties = 0, 0\n",
    "        \n",
    "    if model == 'rcnn' or model == 'rsscnn':\n",
    "        # Ranking sub-network\n",
    "        nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_)\n",
    "    \n",
    "        # Ranking sub-network, without any margin on accuracy\n",
    "        nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "\n",
    "        # Rank difference\n",
    "        avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "        \n",
    "    if model == 'sscnn' or model == 'rsscnn':    \n",
    "        # Classification sub-network\n",
    "        c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'model': model,\n",
    "        'margin': margin_,\n",
    "        'seed': seed,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        'ranking_acc_left': nontie_left_accuracy,\n",
    "        'ranking_acc_right': nontie_right_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        'ranking_acc_left_nomargin': nontie_left_accuracy_nomargin,\n",
    "        'ranking_acc_right_nomargin': nontie_right_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "    }\n",
    "    \n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed51101-7879-49d8-bd83-df44041f67f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92522ec-da47-42f0-bd41-5b276eb5c2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
