{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae26a7-3892-4034-94d5-b733540223b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e80fa-9121-4016-9c2f-10bb28c56a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30768d3d-d20c-4671-8d65-c5c14f0b9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('font',**{'family':'serif',\n",
    "             'serif':['Times New Roman'],\n",
    "             'size': 12,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a8e7d-4e29-462a-a4ee-dfbdf2500bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_accuracy(df_, margin=0):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "    df_ties = df_[df_.label_r == 0]\n",
    "\n",
    "    # Split non ties per their outcome (left and right)\n",
    "    df_nonties_left = df_nonties[(df_nonties.label_r == -1)]\n",
    "    df_nonties_right = df_nonties[(df_nonties.label_r == 1)]\n",
    "\n",
    "    # Non-ties accuracy\n",
    "    correct_left = ((df_nonties.label_r == -1) & (df_nonties.rank_left - df_nonties.rank_right > margin)).sum()\n",
    "    correct_right = ((df_nonties.label_r == 1) & (df_nonties.rank_right - df_nonties.rank_left > margin)).sum()\n",
    "\n",
    "    nontie_left_accuracy = correct_left / (df_nonties.label_r == -1).sum()\n",
    "    nontie_right_accuracy = correct_right / (df_nonties.label_r == 1).sum()\n",
    "    nontie_accuracy = (correct_left + correct_right ) / df_nonties.shape[0]\n",
    "    \n",
    "    # Ties accuracy\n",
    "    tie_accuracy = (abs(df_ties.rank_left - df_ties.rank_right) < margin).sum() / df_ties.shape[0]\n",
    "\n",
    "    # Overall accuracy\n",
    "    overall_accuracy = X_test[((df_.label_r == -1) & (df_.rank_left - df_.rank_right > margin)) |\n",
    "                              ((df_.label_r ==  1) & (df_.rank_right - df_.rank_left > margin)) |\n",
    "                              ((df_.label_r ==  0) & (abs(df_.rank_left - df_.rank_right) < margin))].shape[0] / df_.shape[0]\n",
    "    \n",
    "    return nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a25b3-1981-4c50-b6d3-9623e3aca207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_accuracy_nomargin(df_,):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "\n",
    "    # Split non ties per their outcome (left and right)\n",
    "    df_nonties_left = df_nonties[(df_nonties.label_r == -1)]\n",
    "    df_nonties_right = df_nonties[(df_nonties.label_r == 1)]\n",
    "\n",
    "    # Non-ties accuracy\n",
    "    correct_left = ((df_nonties.label_r == -1) & (df_nonties.rank_left - df_nonties.rank_right > 0)).sum()\n",
    "    correct_right = ((df_nonties.label_r == 1) & (df_nonties.rank_right - df_nonties.rank_left > 0)).sum()\n",
    "\n",
    "    nontie_left_accuracy = correct_left / (df_nonties.label_r == -1).sum()\n",
    "    nontie_right_accuracy = correct_right / (df_nonties.label_r == 1).sum()\n",
    "    nontie_accuracy = (correct_left + correct_right ) / df_nonties.shape[0]\n",
    "\n",
    "    return nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9081b-e0e2-4361-a8d1-dcce08205288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_distance(df_):\n",
    "    # Split in non-ties and ties\n",
    "    df_nonties = df_[df_.label_r != 0]\n",
    "    df_ties = df_[df_.label_r == 0]\n",
    "\n",
    "    # Distance between non-ties\n",
    "    avg_dist_nonties = abs(df_nonties.rank_left - df_nonties.rank_right).mean()\n",
    "    \n",
    "    # Distance between ties\n",
    "    avg_dist_ties = abs(df_ties.rank_left - df_ties.rank_right).mean()\n",
    "    \n",
    "    return avg_dist_nonties, avg_dist_ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab6c8c-343b-4980-a0b2-6da55f591243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(df_):\n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "    if 'logits_0' in df_.columns:\n",
    "        col1_values = df_['logits_l'].values\n",
    "        col2_values = df_['logits_0'].values\n",
    "        col3_values = df_['logits_r'].values\n",
    "            \n",
    "        probabilities = np.apply_along_axis(softmax, axis=1, arr=np.column_stack((col1_values, col2_values, col3_values)))\n",
    "        max_indices = np.argmax(probabilities, axis=1)\n",
    "        # Convert the probabilities back to a DataFrame with appropriate column names\n",
    "        softmax_df = pd.DataFrame(probabilities, columns=['softmax_logit_l', 'softmax_logit_0', 'softmax_logit_r'])\n",
    "        max_index_df = pd.DataFrame({'class_predicted': max_indices})\n",
    "        # Concatenate the new DataFrame with the original DataFrame if needed\n",
    "        result_df = pd.concat([df_.reset_index(drop=True), softmax_df, max_index_df], axis=1,)\n",
    "    \n",
    "        all_accuracy = (result_df.class_predicted == result_df.label_c).sum() / result_df.shape[0]\n",
    "        tie_accuracy = (result_df[result_df.label_c == 1].class_predicted == result_df[result_df.label_c == 1].label_c).sum() / result_df.shape[0]\n",
    "        nontie_accuracy = (result_df[result_df.label_c != 1].class_predicted == result_df[result_df.label_c != 1].label_c).sum() / result_df.shape[0]\n",
    "    \n",
    "    # Without ties\n",
    "    else:\n",
    "        col1_values = df_['logits_l'].values\n",
    "        col3_values = df_['logits_r'].values\n",
    "            \n",
    "        probabilities = np.apply_along_axis(softmax, axis=1, arr=np.column_stack((col1_values, col3_values)))\n",
    "        max_indices = np.argmax(probabilities, axis=1)\n",
    "        # Convert the probabilities back to a DataFrame with appropriate column names\n",
    "        softmax_df = pd.DataFrame(probabilities, columns=['softmax_logit_l', 'softmax_logit_r'])\n",
    "        max_index_df = pd.DataFrame({'class_predicted': max_indices})\n",
    "        # Concatenate the new DataFrame with the original DataFrame if needed\n",
    "        result_df = pd.concat([df_.reset_index(drop=True), softmax_df, max_index_df], axis=1,)\n",
    "    \n",
    "        all_accuracy = (result_df.class_predicted == result_df.label_c).sum() / result_df.shape[0]\n",
    "        tie_accuracy = 0\n",
    "        nontie_accuracy = all_accuracy\n",
    "        \n",
    "    return all_accuracy, tie_accuracy, nontie_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e7db8-1c88-4f2c-aceb-4ed66470a354",
   "metadata": {},
   "source": [
    "## Available results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0162ba-fd9b-4354-8ec0-14a9a88f6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = glob('../outputs/saved/weights/weights_*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5ddf1-39f1-4a2f-850c-aebdedb576a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a204e-877e-4a71-94f7-76803dd35bbb",
   "metadata": {},
   "source": [
    "## Process results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ca657-3a00-464a-937b-5cf6a786d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.basename(model_result).replace('weights_vgg_', '').replace('.pt_results.pkl', '').split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0b7da-c2cf-4171-9595-cd1b4f1e585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_results = []\n",
    "for model_result in model_results:\n",
    "    df = pd.read_pickle(model_result)\n",
    "    \n",
    "    rank_w, tie_w = os.path.basename(model_result).replace('weights_vgg_', '').replace('.pt_results.pkl', '').split('_')\n",
    "    rank_w, tie_w = float(rank_w), float(tie_w)\n",
    "    seed = 30\n",
    "    print('Weights:', rank_w, ' / ', tie_w, '-->', model_result)\n",
    "    margin_ = 0.7\n",
    "\n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val  = train_test_split(X_train, test_size=0.13, random_state=seed)\n",
    "    # print('\\tTrain:     ', X_train.shape)\n",
    "    # print('\\tValidation:', X_val.shape) \n",
    "    # print('\\tTest:      ', X_test.shape)\n",
    "\n",
    "    # Ranking sub-network\n",
    "    nontie_left_accuracy, nontie_right_accuracy, nontie_accuracy, tie_accuracy, overall_accuracy = compute_ranking_accuracy(X_test, margin=margin_)\n",
    "\n",
    "    # Ranking sub-network, without any margin on accuracy\n",
    "    nontie_left_accuracy_nomargin, nontie_right_accuracy_nomargin, nontie_accuracy_nomargin = compute_ranking_accuracy_nomargin(X_test)\n",
    "\n",
    "    # Classification sub-network\n",
    "    c_all_accuracy, c_tie_accuracy, c_nontie_accuracy = compute_classification_accuracy(X_test)\n",
    "\n",
    "    # Rank difference\n",
    "    avg_dist_nonties, avg_dist_ties = compute_ranking_distance(X_test)\n",
    "    \n",
    "    # Compile results\n",
    "    result = {\n",
    "        'rank_w': rank_w,\n",
    "        'tie_w': tie_w,\n",
    "        'seed': seed,\n",
    "        # Ranking, with margins\n",
    "        'ranking_acc': overall_accuracy,\n",
    "        'ranking_acc_nonties': nontie_accuracy,\n",
    "        'ranking_acc_ties': tie_accuracy,\n",
    "        'ranking_acc_left': nontie_left_accuracy,\n",
    "        'ranking_acc_right': nontie_right_accuracy,\n",
    "        # Ranking, without margins\n",
    "        'ranking_acc_nonties_nomargin': nontie_accuracy_nomargin,\n",
    "        'ranking_acc_left_nomargin': nontie_left_accuracy_nomargin,\n",
    "        'ranking_acc_right_nomargin': nontie_right_accuracy_nomargin,\n",
    "        # Classification\n",
    "        'classification_acc': c_all_accuracy,\n",
    "        'classification_acc_nonties': c_nontie_accuracy,\n",
    "        'classification_acc_ties': c_tie_accuracy,\n",
    "        # Rank difference\n",
    "        'avg_dist_nonties': avg_dist_nonties,\n",
    "        'avg_dist_ties': avg_dist_ties,\n",
    "    }\n",
    "    compiled_results.append(result)\n",
    "    \n",
    "results_df = pd.DataFrame(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80028ef-cd06-41b6-853c-62e8e6d46fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.sort_values(by=['rank_w', 'tie_w'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8ffe3-7653-4e62-9a85-ad60b86261a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = results_df[['rank_w', 'tie_w', 'ranking_acc', 'ranking_acc_nonties', 'ranking_acc_ties', 'ranking_acc_nonties_nomargin']]\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f5527-a957-42f0-9ed6-5ae440fb5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb34980-65e2-4834-aa7c-9e7419e6e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection ='3d')\n",
    "ax.plot3D(aa.rank_w, aa.tie_w, aa.ranking_acc_nonties_nomargin, 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768dae7-608d-4cbb-835f-c1984c34576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Helix equation\n",
    "t = np.linspace(0, 10, 50)\n",
    "x, y, z = np.cos(t), np.sin(t), t\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=aa.rank_w, y=aa.tie_w, z=aa.ranking_acc_ties,\n",
    "                                   mode='markers', ),\n",
    "                      go.Scatter3d(x=aa.rank_w, y=aa.tie_w, z=aa.ranking_acc_nonties,\n",
    "                                   mode='markers', )\n",
    "                      ])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b917603-35f9-4057-baa2-9f22a5fe50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.iris()\n",
    "#fig = px.scatter_3d(aa, x='rank_w', y='tie_w', z='ranking_acc_nonties',\n",
    "#              color='rank_w')\n",
    "fig = px.scatter_3d(aa, x='rank_w', y='tie_w', z='ranking_acc_ties',\n",
    "              color='rank_w')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f37082-21c4-455b-8396-1804c7e8adb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
